{
 "metadata": {
  "name": "",
  "signature": "sha256:0a11b103f339f03e7910de3cd0b30886c6bd6889d066394904fb500d14d51439"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "FileIO\n",
      "====\n",
      "\n",
      "So far, when we wanted to read from files, we have either used `pandas`' built-in `read_csv` function, or we have used `codecs`\n",
      "to go through the file line by line.\n",
      "\n",
      "However, in the homework, you might have to deal with large files in either **CSV** or **JSON** format. You could write your own parser for each of those formats, and it would be a great exercise in and of itself, but it's also bound to be tedious and frustrating. Luckily, there are dedicated python modules you can use for them.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "CSV\n",
      "----\n",
      "\n",
      "You have already encountered CSV (comma-spearated value) files. Typically, they are converted spreadhseets, with each line representing a row, and each comma-separated field representing a column (CSV files can have other ***delimiters*** than comma, so whenever we use 'comma' here, you can substitute any character).\n",
      "\n",
      "CSV files need to have the same number of columns in each row, so if a value is missing, we simply have two commas following each other.\n",
      "\n",
      "In case we want to use commas in the data itself, we have to escape them, either by putting a '\\' in front of them, or by wrapping them in quotes. Everything in quotes is then treated as a string, and the quotes themselves are ignored. Naturally, if we want to use quotes in our data, we either need to escape them, or use a different quote to quote the quotes.\n",
      "\n",
      "As you can see, CSV files, despite their rigid structure and simplicity, can come with a lot of headaches. Luckily, the `csv` module provides you with everything to cope with that.\n",
      "\n",
      "In order to read in a CSV file, you simply give it a file handle (i.e., a file that you have opened using `codecs`). If you want to, you can specify the delimiter and quotation characters.\n",
      "\n",
      "The reader then gives you back a list for each line, with one entry for each column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import codecs\n",
      "\n",
      "!cat eggs.csv\n",
      "\n",
      "print\n",
      "with codecs.open('eggs.csv', 'r', encoding='utf-8') as csvfile:\n",
      "    spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
      "    for row in spamreader:\n",
      "        print ', '.join(row)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Spam Spam Spam Spam Spam |Baked Beans|\r",
        "\r\n",
        "Spam Spam Spam |Bacon, Baked Beans, Spam|\r",
        "\r\n",
        "Spam Spam |Bacon, Spam, Eggs, Spam|\r",
        "\r\n",
        "Spam |Lovely Spam| |Wonderful Spam|\r",
        "\r\n",
        "SPAM! |Wonderful Spam| (Spam) (Spam) (Spam) (Spam)\r",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Spam, Spam, Spam, Spam, Spam, Baked Beans\n",
        "Spam, Spam, Spam, Bacon, Baked Beans, Spam\n",
        "Spam, Spam, Bacon, Spam, Eggs, Spam\n",
        "Spam, Lovely Spam, Wonderful Spam\n",
        "SPAM!, Wonderful Spam, (Spam), (Spam), (Spam), (Spam)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "JSON\n",
      "----\n",
      "\n",
      "While the CSV format is easy and common, it has certain drawbacks: you can not vary the number of fields, and it does not allow you to have nested structures or even more complex objects.\n",
      "\n",
      "If you want to store or load, say, a python dictionary that maps from tuples to lists, you'd have to go to great (ok, medium) length to encode it and then read it back in. \n",
      "\n",
      "Writing a programming object as is out to disk is called ***serialization***, and traditionally, people have used pickling or other techniques. The problem with those is that they are not human-readable and often dont work across platforms (Windows to Linux).\n",
      "\n",
      "JSON was designed to be human-readable (it looks like Python code that is written as a string), yet encode complex structures (for example dictionaries which map from tuples to lists). What's even more practical in our case, JSON can be read into Python objects directly, so that you don't have to do any conversions: you can simply get a dictionary from a text file.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with codecs.open('knights.json', 'r', encoding='utf-8') as jsonfile:\n",
      "    for row in jsonfile:\n",
      "        d = json.loads(row)\n",
      "        print type(d), d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'dict'> {u'Sir Gallahad': {u'favorite number': 4, u'shield colors': [u'white', u'green'], u'favorite color': u'red'}}\n",
        "<type 'dict'> {u'Sir Gawain': {u'favorite number': 3, u'shield colors': [u'red', u'blue'], u'favorite color': u'green'}}\n",
        "<type 'dict'> {u'Sir Lancelot': {u'favorite number': 2, u'shield colors': [u'black', u'white', u'ecru'], u'favorite color': u'blue'}}\n",
        "<type 'dict'> {u'King Arthur': {u'favorite number': None, u'shield colors': None, u'favorite color': u'white'}}\n"
       ]
      }
     ],
     "prompt_number": 17
    }
   ],
   "metadata": {}
  }
 ]
}
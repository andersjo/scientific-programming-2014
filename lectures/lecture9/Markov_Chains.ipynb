{
 "metadata": {
  "name": "",
  "signature": "sha256:7aaf0a723b85a03e7971a849f44a332058ed21f985975060206fc40204aa3a0f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Markov Chains\n",
      "====\n",
      "\n",
      "<img src=\"AAMarkov.jpg\", width=200, float=left />\n",
      "\n",
      "Markov Chains are named after a Russian Mathematician, Andrey Markov. Markov Chains are a special kind of weighted directed graphs that describe how how a system changes over time. Each state is thus typically a point in discrete \"time\" (it depends on the problem what exactly a time step is). Markov Chains are thus usually used to predict how a system will develop in the future.\n",
      "\n",
      "The states are the nodes of the graph, and the transitions between them are the edges. Some state transitions are very likely, while others are not likely or even impossible. The edges are thus weighted, and expressed as conditional probability, i.e., what is the chance of going into the next state, given the state I am currently in. This is called the *Markov assumption*, i.e., that you don't take all the previous states into account when predicting the next one. Note that the system can also stay in one state, i.e., the next state is the same as the current one.\n",
      "\n",
      "The sum of the weights of all edges leaving a node has to sum to one!\n",
      "\n",
      "Markov chains are used for weather prediction, market development, speech recognition and NLP (each word is one time step), generational changes, etc.\n",
      "They are also the basis of Hidden Markov Models (HMMs) and Conditional Random Fields (CRFs), two predictive models for structured output.\n",
      "\n",
      "\n",
      "Example: Weather Prediction\n",
      "----\n",
      "\n",
      "While Copenhagen is a fantastic city, constantly rated one of the most liveable worldwide, its weather is probably not factored into these ratings. However, it can serve as an illustration of Markov Chains.\n",
      "\n",
      "Let's say there are three possible weather states:  `overcast`, `rainy`, or `sunny` (i.e., the state space). Let's also say that the next days weather only depends on the weather of today (this is our Markov assumption...). \n",
      "\n",
      "We can represent the state graph like this:\n",
      "\n",
      "<img src=\"328px-Finance_Markov_chain_example_state_space.svg.png\" width=\"400\" />\n",
      "\n",
      "Typically, the weather stays the same for a few days, but occasionally it changes. Our transition matrix looks thus like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#            overc. rainy  sunny\n",
      "P = np.array([[0.9, 0.075, 0.025], # overcast\n",
      "              [0.15, 0.8, 0.05],   # rainy\n",
      "              [0.25, 0.25, 0.5]])  # sunny"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can use the chain for predictions.\n",
      "\n",
      "If today it's sunny, what are the chances for tomorrow? Well, we can simply look at the last row of our transition matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "array([ 0.25,  0.25,  0.5 ])"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So there's a 25% chance of it being overcast or rainy, and a 50% chance of it staying sunny. The mathematical correct way of \"looking at the last row\" is to represent the current state (\"`sunny`\") as a one-hot vector (i.e., everything is $0$ but the current state, which is $1$), and then taking the dot product with $P$:\n",
      "\n",
      "$x \\cdot P$\n",
      "\n",
      "To represent \"`sunny`\", we would thus use\n",
      "`[ 0 0 1 ]`\n",
      "\n",
      "This will give us a distribution over the three possible states (note that the resulting state distribution vector sums to 1.0!)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.dot(np.array([0,0,1]), P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "array([ 0.25,  0.25,  0.5 ])"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This might seem a little counterintuituve at first, but it has a buge advantage: we can do this several times to predict several days ahead into the future! All we have to do for each day is take another dot product with the transition matrix.\n",
      "\n",
      "So if it is rainy today and we want to know the chances for the weather states in three days, we simply take the dot product three times. A little confusingly, this is written as\n",
      "\n",
      "$x \\cdot P^3$\n",
      "\n",
      "(it does **not** mean: raise $P$ to the third power).\n",
      "Again, we get a distribution over the states."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "current = np.array([0,1,0]) # one-hot representation of \"rainy\"\n",
      "\n",
      "# look three days into the future\n",
      "for i in xrange(3):\n",
      "     current = np.dot(current, P)\n",
      "        \n",
      "current"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 135,
       "text": [
        "array([ 0.3575 ,  0.56825,  0.07425])"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks like it's likely to stay rainy for some time...\n",
      "\n",
      "If we repeat this long enough, the distribution converges to a ***stationary distribution***, i.e., in our case, we get the general distribution over weather states in Copenhagen. Note that it does not matter with which state we start."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# start out rainy\n",
      "stable1 = np.array([0,1,0]) # one-hot representation of \"rainy\"\n",
      "\n",
      "# look years into the future\n",
      "for i in xrange(300000):\n",
      "     stable1 = np.dot(stable1, P)\n",
      "        \n",
      "# start out sunny\n",
      "stable2 = np.array([0,0,1]) # one-hot representation of \"sunny\"\n",
      "\n",
      "# look years into the future\n",
      "for i in xrange(300000):\n",
      "     stable2 = np.dot(stable2, P)\n",
      "\n",
      "print 'starting with \"rainy\":', stable1\n",
      "print 'starting with \"sunny\":', stable2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "starting with \"rainy\": [ 0.625   0.3125  0.0625]\n",
        "starting with \"sunny\": [ 0.625   0.3125  0.0625]\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So around 62.5% of the time it is overcast, 31.25% of the time it is rainy, and around 6.25% of the time it is sunny.\n",
      "\n",
      "Higher-order Chains\n",
      "----\n",
      "\n",
      "In the previous example, we only looked at the one day before, so our Markov Chain had a horizon (or history) of 1. This is thus called a ***first-order*** Markov Chain. However, we can have higher-order chains, which represent a relaxed MArkov assumption.\n",
      "\n",
      "If we wanted to base the current weather state on the last **2** days to get a ***second-order*** chain, we'd have to change our transition matrix.\n",
      "\n",
      "Each row is now a sequence of the weather on two days (i.e., '`rainy, rainy`'), so we'd have $3^2=9$ rows and still $3$ columns."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reading\n",
      "====\n",
      "\n",
      "* http://en.wikipedia.org/wiki/Markov_chain"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
{
 "metadata": {
  "name": "",
  "signature": "sha256:f6be99fbda5c5ec93384a9b9a742166ef6a0a9c83540f2de9e1b89aeb4df9569"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Predicting survival for passengers on the Titanic"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In these exercises you will perform statistical analyses and train predictive models to show what kinds of people were most likely to get off the Titanic alive. It is well known that gender and age played a big role (abiding by the [women-and-children-first principle](http://en.wikipedia.org/wiki/Women_and_children_first)), and also passenger class.\n",
      "\n",
      "- Combining \"gender and age\"\n",
      "- Binning age groups (might help with linear classifiers)\n",
      "- Doing cross-validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import sklearn\n",
      "import pandas as pd\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titanic = pd.read_csv(\"titanic_train.csv\", index_col=0)\n",
      "D_train = titanic.copy()\n",
      "labels = titanic.Survived.values\n",
      "\n",
      "# Remove class attribute\n",
      "del D_train['Survived']\n",
      "\n",
      "# Deal with missing values\n",
      "del D_train['Cabin']\n",
      "D_train.Embarked.fillna(D_train.Embarked.mode()[0], inplace=True)\n",
      "D_train.Age.fillna(D_train.Age.mode()[0], inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll start by creating a function that converts a pandas `DataFrame` to a 2-dimensional `numpy` array, returning the array and the vectorizer used to create the array."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import DictVectorizer\n",
      "def vectorize_data_frame(data_frame):\n",
      "    vectorizer = DictVectorizer()\n",
      "    list_of_dicts = data_frame.to_dict('records')\n",
      "    X = vectorizer.fit_transform(list_of_dicts)\n",
      "    \n",
      "    return X, vectorizer\n",
      "\n",
      "X, vectorizer = vectorize_data_frame(D_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training with cross validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When you have small data sets it is often an advantage to use cross-validation. It also alleviates any concern that your test data is not representative of the training data, since in the end all of the training data will be used for testing.\n",
      "\n",
      "In sklearn you have several methods for performing cross validation at your disposal. The two most common methods methods are:\n",
      "\n",
      "- The function `cross_val_score` from the `cross_validation` module. If you are only interested in a single performance figure, like accuracy or F1, this is the way to go.\n",
      "- A cross-validation generator, also available in the `cross_validation` module. Used in a `for` loop it yields for each iteration a tuple with training set indices and and test set indices."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Compute the average F1 score using a logistic regression classifier and a 5 fold stratified cross validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code below\n",
      "\n",
      "# AJ remove code\n",
      "clf = LogisticRegression()\n",
      "scores = cross_validation.cross_val_score(clf, X, labels, scoring='f1', cv=5)\n",
      "scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Use the `StratifiedKFold` cross-validation strategy to get predicted labels for the entire training set. Do this in a `for` loop. Set $k=5$ and compute the F1 score.\n",
      "\n",
      "Hint: Start by initializing an `numpy` array to hold the predicted classes for the whole training set. It is good practice to fill the array with a value which cannot be mistaken for a class, e.g. **-1**, to make sure that you will notice in case not all of the values were updated by the `for` loop."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "\n",
      "# AJ remove code\n",
      "from sklearn.metrics import precision_score, classification_report\n",
      "y_pred = np.ones(X.shape[0]) * -1\n",
      "for train_idx, test_idx in cross_validation.StratifiedKFold(labels, n_folds=5):\n",
      "    clf = LogisticRegression()\n",
      "    clf.fit(X[train_idx], labels[train_idx])\n",
      "    y_pred[test_idx] = clf.predict(X[test_idx])\n",
      "\n",
      "f1_score(labels, y_pred)\n",
      "#print classification_report(labels, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Creating new attributes based on existing ones"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Two of the attributes in the dataset conflate different measures. According to the documentation, *SibSp* is the number of siblings *and* spouses, and *Parch* denotes number of parents *and* children. In most cases, though, you would either have siblings *or* spouses, and parents *or* children. Here we try to create non-conflated versions of the attributes by assuming that if you are a child, *Sibsp* means siblings, and if you are an adult, the attributes refers to spouses. By a similar logic *Parch* means parents for children and children for adults.\n",
      "\n",
      "```\n",
      "sibsp           Number of Siblings/Spouses Aboard\n",
      "parch           Number of Parents/Children Aboard\n",
      "```\n",
      "\n",
      "**Exercise** Add five new attributes to the training set `D_train` as indicated below:\n",
      "\n",
      "* `Is_child`: True when the person is below 16 years\n",
      "* `Sib`: Number of siblings\n",
      "* `Sp`: Number of spouses\n",
      "* `Par`: Number of parents\n",
      "* `Ch`: Number of children"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "\n",
      "# AJ remove code\n",
      "D_train['Is_child'] = D_train.Age < 16\n",
      "D_train['Sib'] = np.where(D_train.Is_child, D_train.SibSp, 0)\n",
      "D_train['Sp'] = np.where(~D_train.Is_child, D_train.SibSp, 0)\n",
      "D_train['Par'] = np.where(D_train.Is_child, D_train.Parch, 0)\n",
      "D_train['Ch'] = np.where(~D_train.Is_child, D_train.Parch, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Compute F1 using 5-fold CV for the augmented dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "\n",
      "# AJ remove code\n",
      "clf = LogisticRegression()\n",
      "X, vectorizer = vectorize_data_frame(D_train)\n",
      "scores = cross_validation.cross_val_score(clf, X, labels, scoring='f1', cv=5)\n",
      "scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Binning age groups"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this exercise you should bin the values of the `Age` column into 10 year spans.\n",
      "\n",
      "**Exercise** Start by making histograms of the age distribution, with different histograms for individuals with `Survived=True`  and `Survived=False`. Each bin should correspond to a single year. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Create a new column `Age_group` binning the values of `Age` into ten year ranges. The values of this column should be strings of the form:\n",
      "\n",
      "````\n",
      "00-09\n",
      "10-19\n",
      "20-29\n",
      "...\n",
      "````\n",
      "\n",
      "Output the contents of the new column at the end of the cell."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Make a table displaying the mean survival rate in the different age groups. You can also try to look at survival rates for more specific subgroups by grouping on multiple columns at the same time, e.g. `Age_group` and `Sex`, or `Age_group` and `Sib`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Run CV with same parameters as in the last exercise. Also try to remove the original Age attribute to see if that makes any difference."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Optional: Undoing previous preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataset includes a column with the number of the cabin, if available, which we removed due to sparsity. However, this might be throwing away valuable information. Encoded in the cabin number is the location of the cabin, something which conceviably has a great influence on a person's survival chances. \n",
      "\n",
      "![Plan of Titanic](http://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Titanic_side_plan_1911.png/1280px-Titanic_side_plan_1911.png)\n",
      "\n",
      "As an optional exercise you can extract this information into new columns and see if it improves model performance. Here are a couple of suggestions:\n",
      "\n",
      "* Create columns `At_deck_X` (for decks A to G), which is True if the cabin is on that floor, and false otherwise. Pandas has useful vectorized string functions which makes this easy to do. For instance, `titanic.Cabin.str.contains(\"A\")` gives back True for the instances in which the Cabin column contains an \"A\".\n",
      "* Create columns `At_deck_X_or_below`, which is True if the cabin is on the given floor or any lower floor.\n",
      "* Create a column `Deck` that maps the deck letters (\"A\" through \"G\") to numbers. If you do this you have to be careful about what you put in as missing values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
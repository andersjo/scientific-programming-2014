{
 "metadata": {
  "name": "",
  "signature": "sha256:b2101e395b780ac9467d192f71bd8c2b2f3295289526b5d41ef2e9b0c65563a5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Detecting the language of a sentence using a Bloom filter"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this exercise you will be implementing a simple language detector, which uses a Bloom filter as its main data structure. For training and testing the code, we use sentences from company reviews, originally posted on [Trustpilot](trustpilot.com).\n",
      "\n",
      "We begin by defining additional hash functions. \n",
      "\n",
      "In the cell below, `random_integers` is initialized with large non-negative integers. Each of the functions combine a different random number with the output of the Python `hash` function using a binary *XOR* operation. \n",
      "\n",
      "(If you haven't heard about *XOR* before, don't worry: it's not essential. Suffice to say that `hash1`, `hash2`, and `hash3` are three different hash functions.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "import sys\n",
      "import codecs\n",
      "\n",
      "random_integers = [random.randrange(0, sys.maxint) for i in range(10)]\n",
      "def hash1(obj): \n",
      "    return hash(obj) ^ random_integers[0] # ^ is XOR\n",
      "\n",
      "def hash2(obj):\n",
      "    return hash(obj) ^ random_integers[1]\n",
      "\n",
      "def hash3(obj):\n",
      "    return hash(obj) ^ random_integers[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Verify that the hash functions defined above are indeed different. Test it by hand with a couple of strings of your choice."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Next define a class `BloomFilter`, in which the initializer takes an argument `filter_size` and fills the backing data structure with zeros. The filter should implement two methods:\n",
      "\n",
      "- `add` which adds a string to the bloom filter; and \n",
      "- `is_in` which returns `True` if the filter (probably) contains the string and `False` if it definitely doesn't."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your class definition here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below we read in a sample of ten thousand sentences of French and English, taken from the trustpilot.com site. The function discards any token with non-alphabetic character. This skips URLs, numbers, punctuation, etc."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_review_sentences(filename):\n",
      "    sentences = []\n",
      "    for line in codecs.open(filename, encoding='utf-8'):\n",
      "        tokens = line.strip().split(\" \")\n",
      "        tokens = [token for token in tokens if token.isalpha()]\n",
      "        sentences.append(tokens)\n",
      "    return sentences\n",
      "        \n",
      "en_sentences = read_review_sentences(\"trust_pilot.10k.english\")\n",
      "fr_sentences = read_review_sentences(\"trust_pilot.10k.french\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We divide the sentences up into a *training* and a *testing* section."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "en_sentences_train = en_sentences[:8000]\n",
      "en_sentences_test = en_sentences[8000:]\n",
      "\n",
      "fr_sentences_train = fr_sentences[:8000]\n",
      "fr_sentences_test = fr_sentences[8000:]                      "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Train two bloom filters, one for each of the languages. \"Training\" consists of adding all the tokens in the sample to the filter. Use a filter size of 100000."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Below you shuld evaluate how accurate the language detector is. Provide the implementation of the `is_french` function. It should return `True` whenever the number of French words in a sentence exceeds the number of English words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_french(sent):\n",
      "    return True\n",
      "\n",
      "french_scores = [is_french(sent) for sent in fr_sentences_test] \n",
      "english_scores = [not is_french(sent) for sent in en_sentences_test]\n",
      "\n",
      "print \"French accuracy\", sum(french_scores) / float(len(french_scores))\n",
      "print \"English accuracy\", sum(english_scores) / float(len(english_scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "French accuracy 1.0\n",
        "English accuracy 0.0\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Modify the `filter_size`, adjusting it up and down. Try different values and observe the influence on the language detection accuracies. Does filter size affect both languages equally?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    }
   ],
   "metadata": {}
  }
 ]
}